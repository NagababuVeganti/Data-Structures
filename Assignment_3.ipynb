{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NagababuVeganti/Data-Structures/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPC-9Qh4oUDY"
      },
      "source": [
        "# Assignment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EabSaI_4oUDZ"
      },
      "source": [
        "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkq81suqoUDZ"
      },
      "source": [
        "## Description of Variables\n",
        "\n",
        "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
        "\n",
        "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
        "0 = Normal<br>\n",
        "1 = Supraventricular premature beat<br>\n",
        "2 = Premature ventricular contraction<br>\n",
        "3 = Fusion of ventricular and normal beat<br>\n",
        "4 = Unclassifiable beat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRgbnhxvoUDa"
      },
      "source": [
        "## Goal\n",
        "\n",
        "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu6OrAMBoUDa"
      },
      "source": [
        "## Submission:\n",
        "\n",
        "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP5Uo2MToUDa"
      },
      "source": [
        "# Note:\n",
        "\n",
        "The data is cleaned up. There are no unqueal length sequences. And, there is no zero padding. So, you shouldn't use any `Masking` layer (like I mentioned in the lecture). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCYW5pj1oUDa"
      },
      "source": [
        "# Read and Prepare the Data (1 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqFjp0B2oUDa"
      },
      "outputs": [],
      "source": [
        "# Insert as many cells as you need for data prep"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Common Imports**"
      ],
      "metadata": {
        "id": "sRecgWIwyWGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cy3y9kofoUDa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import keras\n",
        "import tensorflow as tf\n",
        "np.random.seed(46046025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Al273ZukoUDb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reading Data**"
      ],
      "metadata": {
        "id": "FQG0M4jfy1Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('heartbeat_cleaned.csv',index_col=0)"
      ],
      "metadata": {
        "id": "sQbam8LIy4TK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "9oSpXQT0y4gr",
        "outputId": "8417b51f-647f-4850-a397-c7873f810775"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
              "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
              "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
              "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
              "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
              "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
              "\n",
              "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
              "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
              "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
              "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
              "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
              "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
              "\n",
              "      T80  Target  \n",
              "0  0.2080     0.0  \n",
              "1  0.1720     0.0  \n",
              "2  0.0519     0.0  \n",
              "3  0.8690     0.0  \n",
              "4  0.0628     0.0  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05413f6f-f531-40a5-93f2-f5cd7f64110e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>T3</th>\n",
              "      <th>T4</th>\n",
              "      <th>T5</th>\n",
              "      <th>T6</th>\n",
              "      <th>T7</th>\n",
              "      <th>T8</th>\n",
              "      <th>T9</th>\n",
              "      <th>T10</th>\n",
              "      <th>...</th>\n",
              "      <th>T72</th>\n",
              "      <th>T73</th>\n",
              "      <th>T74</th>\n",
              "      <th>T75</th>\n",
              "      <th>T76</th>\n",
              "      <th>T77</th>\n",
              "      <th>T78</th>\n",
              "      <th>T79</th>\n",
              "      <th>T80</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.987</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.461</td>\n",
              "      <td>0.1130</td>\n",
              "      <td>0.1490</td>\n",
              "      <td>0.1900</td>\n",
              "      <td>0.1650</td>\n",
              "      <td>0.1620</td>\n",
              "      <td>0.1470</td>\n",
              "      <td>0.1380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1960</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.1990</td>\n",
              "      <td>0.2010</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.2080</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.918</td>\n",
              "      <td>0.621</td>\n",
              "      <td>0.1330</td>\n",
              "      <td>0.1050</td>\n",
              "      <td>0.1250</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.0898</td>\n",
              "      <td>0.0703</td>\n",
              "      <td>0.0781</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>0.1910</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>0.1720</td>\n",
              "      <td>0.207</td>\n",
              "      <td>0.2110</td>\n",
              "      <td>0.2070</td>\n",
              "      <td>0.207</td>\n",
              "      <td>0.1720</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.1040</td>\n",
              "      <td>0.0961</td>\n",
              "      <td>0.0519</td>\n",
              "      <td>0.0442</td>\n",
              "      <td>0.0416</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.0857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2260</td>\n",
              "      <td>0.2420</td>\n",
              "      <td>0.2440</td>\n",
              "      <td>0.2860</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.8160</td>\n",
              "      <td>0.9770</td>\n",
              "      <td>0.452</td>\n",
              "      <td>0.0519</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.740</td>\n",
              "      <td>0.235</td>\n",
              "      <td>0.0464</td>\n",
              "      <td>0.0722</td>\n",
              "      <td>0.0567</td>\n",
              "      <td>0.0103</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0851</td>\n",
              "      <td>0.0747</td>\n",
              "      <td>0.0515</td>\n",
              "      <td>0.0593</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.0361</td>\n",
              "      <td>0.1210</td>\n",
              "      <td>0.451</td>\n",
              "      <td>0.8690</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.309</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>0.1040</td>\n",
              "      <td>0.0874</td>\n",
              "      <td>0.0765</td>\n",
              "      <td>0.0765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4210</td>\n",
              "      <td>0.8030</td>\n",
              "      <td>0.9510</td>\n",
              "      <td>0.467</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0519</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.0628</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05413f6f-f531-40a5-93f2-f5cd7f64110e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05413f6f-f531-40a5-93f2-f5cd7f64110e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05413f6f-f531-40a5-93f2-f5cd7f64110e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting Few Rows to see trends**"
      ],
      "metadata": {
        "id": "DlhezOl32TS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2,ax3,ax4) = plt.subplots(4)\n",
        "ax1.plot(data.iloc[0])\n",
        "ax2.plot(data.iloc[1])\n",
        "ax3.plot(data.iloc[2])\n",
        "ax4.plot(data.iloc[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "xO_wPPv-1v0q",
        "outputId": "9dc2ebe1-ceec-4258-a080-c2eee2c69b40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f73f191e490>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7kRQ3KSs0JFf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As mentioned in the description ecah. row in the  dataset represents a single measurement (captured on a timeline). There are a total of 80 data points (columns).**"
      ],
      "metadata": {
        "id": "ww87qjuzzSh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e2AqlCR10KGT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(data, test_size=0.3)"
      ],
      "metadata": {
        "id": "i49FUXO20Re-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k-t3TCUt0Rh0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separate the target variable (we don't want to transform it)"
      ],
      "metadata": {
        "id": "jWVeKAnr1Ipc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_target = train_set[['Target']]\n",
        "test_target = test_set[['Target']]\n",
        "\n",
        "train_inputs = train_set.drop(['Target'], axis=1)\n",
        "test_inputs = test_set.drop(['Target'], axis=1)"
      ],
      "metadata": {
        "id": "64n1BVsG1H73"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding the Target column**"
      ],
      "metadata": {
        "id": "x-SgsdxB6TYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ord_enc = OrdinalEncoder()\n",
        "\n",
        "train_y = ord_enc.fit_transform(train_target)\n",
        "\n",
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA7iBNqI6Siv",
        "outputId": "47427825-eeb2-45cf-ceaa-5dd518f63792"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.],\n",
              "       [2.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying it for test also\n",
        "test_y = ord_enc.transform(test_target)\n",
        "\n",
        "test_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7x6_ZvK6Svg",
        "outputId": "d55a89bb-077a-4c5e-cc8c-69faeeb3e1c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.],\n",
              "       [2.],\n",
              "       [4.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Sanity Checks**"
      ],
      "metadata": {
        "id": "NdhnBotM0LEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Check for Missing Values**"
      ],
      "metadata": {
        "id": "7Sw_GIoJ0cPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqnTqBQG0KJt",
        "outputId": "5ab141c4-1275-40f7-9e93-ca7361d4444c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T1        0\n",
              "T2        0\n",
              "T3        0\n",
              "T4        0\n",
              "T5        0\n",
              "         ..\n",
              "T77       0\n",
              "T78       0\n",
              "T79       0\n",
              "T80       0\n",
              "Target    0\n",
              "Length: 81, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d49TszqL0KM0",
        "outputId": "d9b8769b-4577-431f-f5b8-f8a162799228"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T1        0\n",
              "T2        0\n",
              "T3        0\n",
              "T4        0\n",
              "T5        0\n",
              "         ..\n",
              "T77       0\n",
              "T78       0\n",
              "T79       0\n",
              "T80       0\n",
              "Target    0\n",
              "Length: 81, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude that data set is clean "
      ],
      "metadata": {
        "id": "GWVPOxav0lNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yGh1SYzT0Ko9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILgwDfDGoUDb"
      },
      "source": [
        "# Find the baseline (0.5 point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeDqIjTMoUDb",
        "outputId": "b46e5516-fd3d-43a4-c8bf-c546e176e63a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target\n",
              "0.0       0.572864\n",
              "4.0       0.203338\n",
              "2.0       0.160804\n",
              "1.0       0.054738\n",
              "3.0       0.008256\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "train_target.value_counts()/len(train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "h50-Yi5GoUDb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0hIH8rioUDb"
      },
      "source": [
        "# Build a cross-sectional shallow model using Keras (with only one hidden layer) (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "YjUlKbXPoUDb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "tf.random.set_seed(46046025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn9bHM-noUDb",
        "outputId": "34101103-5073-4fe7-ac45-78e7ccd9399a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 80)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "#Checking the shape of the datset to define the input dimenssions of the model\n",
        "\n",
        "train_inputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1**(Adam Optimizer)"
      ],
      "metadata": {
        "id": "qJzFmiHq81y1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pWZDvKQnoUDb"
      },
      "outputs": [],
      "source": [
        "#Define the model: for multi-class\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Input(shape=80))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "#final layer: there has to be 5 nodes with softmax layer since we have 5 categories in the target label.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "\n",
        "#Optimizer using Adam optimizer\n",
        "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dLCz-WII8zpG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "history = model.fit(train_inputs, train_y, \n",
        "                    validation_data=(test_inputs, test_y), \n",
        "                    epochs=50, batch_size=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7Y7cIBP8zs9",
        "outputId": "af4953ff-1a8c-4a0b-988b-23a0a25a54b1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 1.1300 - accuracy: 0.6018 - val_loss: 0.8129 - val_accuracy: 0.7701\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7687 - accuracy: 0.7717 - val_loss: 0.6690 - val_accuracy: 0.7718\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6853 - accuracy: 0.7854 - val_loss: 0.6360 - val_accuracy: 0.8074\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6486 - accuracy: 0.8001 - val_loss: 0.5988 - val_accuracy: 0.8107\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6083 - accuracy: 0.8004 - val_loss: 0.5521 - val_accuracy: 0.8204\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5582 - accuracy: 0.8157 - val_loss: 0.5090 - val_accuracy: 0.8162\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.8204 - val_loss: 0.4669 - val_accuracy: 0.8559\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.8335 - val_loss: 0.4452 - val_accuracy: 0.8497\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.8476 - val_loss: 0.4180 - val_accuracy: 0.8723\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.8634 - val_loss: 0.4091 - val_accuracy: 0.8915\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8720 - val_loss: 0.3956 - val_accuracy: 0.8802\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8758 - val_loss: 0.4364 - val_accuracy: 0.8723\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8715 - val_loss: 0.3831 - val_accuracy: 0.8991\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8880 - val_loss: 0.3739 - val_accuracy: 0.8823\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8871 - val_loss: 0.3717 - val_accuracy: 0.8957\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8826 - val_loss: 0.4195 - val_accuracy: 0.8756\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8877 - val_loss: 0.3686 - val_accuracy: 0.8987\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8914 - val_loss: 0.3431 - val_accuracy: 0.9100\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8991 - val_loss: 0.3434 - val_accuracy: 0.9133\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8957 - val_loss: 0.3388 - val_accuracy: 0.9079\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.9024 - val_loss: 0.3404 - val_accuracy: 0.9033\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.9081 - val_loss: 0.3295 - val_accuracy: 0.9066\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3199 - accuracy: 0.9097 - val_loss: 0.3278 - val_accuracy: 0.9100\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3225 - accuracy: 0.9087 - val_loss: 0.3210 - val_accuracy: 0.9196\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.9151 - val_loss: 0.3189 - val_accuracy: 0.9162\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3092 - accuracy: 0.9142 - val_loss: 0.3275 - val_accuracy: 0.9041\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3098 - accuracy: 0.9103 - val_loss: 0.3192 - val_accuracy: 0.9137\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3056 - accuracy: 0.9142 - val_loss: 0.3161 - val_accuracy: 0.9146\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.9119 - val_loss: 0.3028 - val_accuracy: 0.9213\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2916 - accuracy: 0.9165 - val_loss: 0.3171 - val_accuracy: 0.9162\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.9128 - val_loss: 0.3053 - val_accuracy: 0.9221\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2938 - accuracy: 0.9167 - val_loss: 0.3004 - val_accuracy: 0.9238\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2868 - accuracy: 0.9196 - val_loss: 0.3093 - val_accuracy: 0.9217\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2833 - accuracy: 0.9207 - val_loss: 0.2945 - val_accuracy: 0.9238\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2761 - accuracy: 0.9221 - val_loss: 0.2920 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2745 - accuracy: 0.9223 - val_loss: 0.2971 - val_accuracy: 0.9225\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2793 - accuracy: 0.9203 - val_loss: 0.3335 - val_accuracy: 0.9112\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2868 - accuracy: 0.9171 - val_loss: 0.2944 - val_accuracy: 0.9221\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2695 - accuracy: 0.9226 - val_loss: 0.2883 - val_accuracy: 0.9246\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2707 - accuracy: 0.9243 - val_loss: 0.3096 - val_accuracy: 0.9125\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2759 - accuracy: 0.9210 - val_loss: 0.2921 - val_accuracy: 0.9250\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2673 - accuracy: 0.9232 - val_loss: 0.2817 - val_accuracy: 0.9234\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2704 - accuracy: 0.9221 - val_loss: 0.3054 - val_accuracy: 0.9133\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2642 - accuracy: 0.9216 - val_loss: 0.2837 - val_accuracy: 0.9234\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.9253 - val_loss: 0.2835 - val_accuracy: 0.9234\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.9271 - val_loss: 0.2847 - val_accuracy: 0.9238\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.9284 - val_loss: 0.2733 - val_accuracy: 0.9284\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 0.9262 - val_loss: 0.2834 - val_accuracy: 0.9234\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2472 - accuracy: 0.9271 - val_loss: 0.2841 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2509 - accuracy: 0.9248 - val_loss: 0.2815 - val_accuracy: 0.9229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "\n",
        "scores = model.evaluate(test_inputs, test_y, verbose=0)\n",
        "\n",
        "scores\n",
        "\n",
        "# In results, first is loss, second is accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb2yPqaF_xlt",
        "outputId": "951b5a8d-8249-4dee-e2c6-73cd85c3bb89"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28153911232948303, 0.9229480624198914]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the accuracy from model.evaluate\n",
        "\n",
        "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKwsECEL_xpE",
        "outputId": "c9ff1a83-53e0-44aa-9de5-f159c8f8baab"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.28\n",
            "accuracy: 92.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`**Note:**` In the above model i tried different epochs and i found that as we increase the number of epochs the accuray also started to increse, when i tried with 20 epochs i got an accuracy of `90.2%` and when i increaed the number of epochs to 50 the accuracy increased to `92.22%` "
      ],
      "metadata": {
        "id": "Oplqdhxi94S0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sub-Model (Optimizer: RMSprop)"
      ],
      "metadata": {
        "id": "tbpOSeHY-fGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I looked up the Keras documentation to find other available optimizers(https://keras.io/api/optimizers/)"
      ],
      "metadata": {
        "id": "_RcFTULJ_CkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model: for multi-class\n",
        "\n",
        "sub_model = keras.models.Sequential()\n",
        "\n",
        "sub_model.add(keras.layers.Input(shape=80))\n",
        "sub_model.add(keras.layers.Dense(150, activation='relu'))\n",
        "sub_model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "#final layer: there has to be 5 nodes with softmax layer since we have 5 categories in the target label.\n"
      ],
      "metadata": {
        "id": "dUEhzoYx9gj0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "\n",
        "#Optimizer using Adam optimizer\n",
        "adam = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.02)\n",
        "\n",
        "sub_model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xkmtOUa_9gm6"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "history = sub_model.fit(train_inputs, train_y, \n",
        "                    validation_data=(test_inputs, test_y), \n",
        "                    epochs=50, batch_size=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-KLxenD9gql",
        "outputId": "0fe25b0d-4634-4e0c-931f-234dc511815a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 1.3819 - accuracy: 0.4885 - val_loss: 1.1462 - val_accuracy: 0.5779\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9282 - accuracy: 0.6734 - val_loss: 0.9052 - val_accuracy: 0.7508\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7996 - accuracy: 0.7457 - val_loss: 0.6518 - val_accuracy: 0.8103\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7148 - accuracy: 0.7678 - val_loss: 0.7967 - val_accuracy: 0.7399\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6748 - accuracy: 0.7721 - val_loss: 0.5718 - val_accuracy: 0.8082\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6222 - accuracy: 0.7850 - val_loss: 0.5581 - val_accuracy: 0.8178\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.8062 - val_loss: 0.7139 - val_accuracy: 0.7265\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5783 - accuracy: 0.7994 - val_loss: 0.4910 - val_accuracy: 0.8312\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.8186 - val_loss: 0.5224 - val_accuracy: 0.8241\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.8126 - val_loss: 0.5330 - val_accuracy: 0.8053\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4844 - accuracy: 0.8291 - val_loss: 0.6589 - val_accuracy: 0.7542\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.8252 - val_loss: 0.4970 - val_accuracy: 0.8484\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.8396 - val_loss: 0.4140 - val_accuracy: 0.8446\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.8460 - val_loss: 0.4618 - val_accuracy: 0.8543\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8505 - val_loss: 0.4327 - val_accuracy: 0.8702\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.8568 - val_loss: 0.6348 - val_accuracy: 0.7688\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8623 - val_loss: 0.7100 - val_accuracy: 0.6717\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8505 - val_loss: 0.3815 - val_accuracy: 0.8987\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8654 - val_loss: 0.3759 - val_accuracy: 0.8668\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8546 - val_loss: 0.3848 - val_accuracy: 0.8723\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8720 - val_loss: 0.3727 - val_accuracy: 0.8807\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8706 - val_loss: 0.5370 - val_accuracy: 0.8241\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.5184 - val_accuracy: 0.8262\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3627 - accuracy: 0.8830 - val_loss: 0.4497 - val_accuracy: 0.8371\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3567 - accuracy: 0.8841 - val_loss: 0.4565 - val_accuracy: 0.8664\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3364 - accuracy: 0.8961 - val_loss: 0.3942 - val_accuracy: 0.8798\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8740 - val_loss: 0.3635 - val_accuracy: 0.8685\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8950 - val_loss: 0.4452 - val_accuracy: 0.8484\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8751 - val_loss: 0.3215 - val_accuracy: 0.9075\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3028 - accuracy: 0.9038 - val_loss: 0.4147 - val_accuracy: 0.8756\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.8961 - val_loss: 0.3521 - val_accuracy: 0.8978\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3154 - accuracy: 0.8999 - val_loss: 0.3361 - val_accuracy: 0.8932\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3246 - accuracy: 0.8970 - val_loss: 0.3160 - val_accuracy: 0.9112\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3073 - accuracy: 0.9040 - val_loss: 0.4748 - val_accuracy: 0.8693\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3375 - accuracy: 0.8934 - val_loss: 0.3188 - val_accuracy: 0.9133\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3094 - accuracy: 0.9034 - val_loss: 0.2926 - val_accuracy: 0.9188\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3086 - accuracy: 0.9052 - val_loss: 0.3352 - val_accuracy: 0.9095\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3303 - accuracy: 0.8990 - val_loss: 0.3405 - val_accuracy: 0.8974\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2715 - accuracy: 0.9187 - val_loss: 0.4761 - val_accuracy: 0.8354\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3400 - accuracy: 0.8943 - val_loss: 0.4431 - val_accuracy: 0.8832\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2795 - accuracy: 0.9140 - val_loss: 0.3821 - val_accuracy: 0.8673\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 0.9128 - val_loss: 0.4559 - val_accuracy: 0.8505\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.9078 - val_loss: 0.3256 - val_accuracy: 0.9045\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2905 - accuracy: 0.9070 - val_loss: 0.2852 - val_accuracy: 0.9221\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.9228 - val_loss: 0.3142 - val_accuracy: 0.9146\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.9207 - val_loss: 0.3220 - val_accuracy: 0.9112\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2925 - accuracy: 0.9065 - val_loss: 0.2816 - val_accuracy: 0.9271\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2797 - accuracy: 0.9140 - val_loss: 0.3095 - val_accuracy: 0.9062\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2684 - accuracy: 0.9146 - val_loss: 0.3260 - val_accuracy: 0.8999\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2781 - accuracy: 0.9090 - val_loss: 0.4883 - val_accuracy: 0.8702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "\n",
        "scores = sub_model.evaluate(test_inputs, test_y, verbose=0)\n",
        "\n",
        "scores\n",
        "\n",
        "# In results, first is loss, second is accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOCFGKzt9gtK",
        "outputId": "750698d7-d8c2-4813-edeb-4395f9306905"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4882899522781372, 0.8701842427253723]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the accuracy from model.evaluate\n",
        "\n",
        "print(\"%s: %.2f\" % (sub_model.metrics_names[0], scores[0]))\n",
        "print(\"%s: %.2f%%\" % (sub_model.metrics_names[1], scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwpDfAEn9gwB",
        "outputId": "1458770b-2599-4f42-95d1-7955c5a0c2b0"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.49\n",
            "accuracy: 87.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we can see that Adam optimizer perforemed better compared to RMSprop for same number of Epochs"
      ],
      "metadata": {
        "id": "EQyF4RsuI7lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UpRtAdEX9g1I"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqFRI-LWoUDb"
      },
      "source": [
        "# Build a cross-sectional deep model using Keras (with two or more hidden layers) (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ga8lqwhQoUDb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1 (Adam Optimizer)**"
      ],
      "metadata": {
        "id": "v4sWKB5tJPU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "8qmt4dlPoUDb"
      },
      "outputs": [],
      "source": [
        "#Define the model: for multi-class\n",
        "\n",
        "sub_model_multi = keras.models.Sequential()\n",
        "\n",
        "sub_model_multi.add(keras.layers.Input(shape=80))\n",
        "sub_model_multi.add(keras.layers.Dense(75, activation='relu'))\n",
        "sub_model_multi.add(keras.layers.Dense(150, activation='relu'))\n",
        "sub_model_multi.add(keras.layers.Dense(75, activation='relu'))\n",
        "sub_model_multi.add(keras.layers.Dense(5, activation='softmax'))\n",
        "#final layer: there has to be 5 nodes with softmax layer since we have 5 categories in the target label.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "\n",
        "#Optimizer using Adam optimizer\n",
        "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "sub_model_multi.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y10wLnBYJjVp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "history = sub_model_multi.fit(train_inputs, train_y, \n",
        "                    validation_data=(test_inputs, test_y), \n",
        "                    epochs=50, batch_size=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bueA_kagJjai",
        "outputId": "ab4c607d-69a3-4026-ce8c-52ce2b51761d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 25ms/step - loss: 1.0182 - accuracy: 0.6226 - val_loss: 0.8204 - val_accuracy: 0.7186\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6994 - accuracy: 0.7548 - val_loss: 0.5824 - val_accuracy: 0.8040\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5734 - accuracy: 0.7997 - val_loss: 0.4912 - val_accuracy: 0.8367\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4801 - accuracy: 0.8439 - val_loss: 0.4705 - val_accuracy: 0.8601\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4348 - accuracy: 0.8684 - val_loss: 0.3964 - val_accuracy: 0.8756\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4000 - accuracy: 0.8699 - val_loss: 0.4391 - val_accuracy: 0.8543\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3765 - accuracy: 0.8837 - val_loss: 0.3509 - val_accuracy: 0.9095\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3333 - accuracy: 0.8964 - val_loss: 0.3280 - val_accuracy: 0.9137\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3072 - accuracy: 0.9067 - val_loss: 0.3498 - val_accuracy: 0.9003\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3286 - accuracy: 0.8961 - val_loss: 0.3088 - val_accuracy: 0.9154\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2796 - accuracy: 0.9133 - val_loss: 0.2882 - val_accuracy: 0.9204\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2635 - accuracy: 0.9169 - val_loss: 0.2973 - val_accuracy: 0.9112\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2612 - accuracy: 0.9198 - val_loss: 0.3109 - val_accuracy: 0.9188\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2447 - accuracy: 0.9246 - val_loss: 0.3199 - val_accuracy: 0.8995\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2413 - accuracy: 0.9235 - val_loss: 0.2911 - val_accuracy: 0.9204\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2495 - accuracy: 0.9214 - val_loss: 0.3062 - val_accuracy: 0.9016\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2617 - accuracy: 0.9156 - val_loss: 0.2811 - val_accuracy: 0.9150\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2340 - accuracy: 0.9266 - val_loss: 0.2611 - val_accuracy: 0.9267\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2183 - accuracy: 0.9298 - val_loss: 0.2689 - val_accuracy: 0.9200\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2213 - accuracy: 0.9316 - val_loss: 0.2466 - val_accuracy: 0.9259\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2030 - accuracy: 0.9332 - val_loss: 0.2761 - val_accuracy: 0.9271\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2122 - accuracy: 0.9365 - val_loss: 0.2434 - val_accuracy: 0.9313\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1892 - accuracy: 0.9386 - val_loss: 0.2319 - val_accuracy: 0.9334\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1845 - accuracy: 0.9415 - val_loss: 0.2304 - val_accuracy: 0.9363\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1691 - accuracy: 0.9471 - val_loss: 0.2480 - val_accuracy: 0.9313\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1749 - accuracy: 0.9463 - val_loss: 0.2277 - val_accuracy: 0.9359\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1682 - accuracy: 0.9435 - val_loss: 0.2629 - val_accuracy: 0.9225\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1887 - accuracy: 0.9377 - val_loss: 0.2273 - val_accuracy: 0.9317\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1825 - accuracy: 0.9411 - val_loss: 0.2307 - val_accuracy: 0.9347\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 0.9490 - val_loss: 0.2430 - val_accuracy: 0.9284\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1579 - accuracy: 0.9487 - val_loss: 0.2437 - val_accuracy: 0.9372\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1616 - accuracy: 0.9483 - val_loss: 0.2225 - val_accuracy: 0.9363\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1669 - accuracy: 0.9460 - val_loss: 0.2601 - val_accuracy: 0.9288\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1534 - accuracy: 0.9481 - val_loss: 0.2288 - val_accuracy: 0.9389\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1404 - accuracy: 0.9560 - val_loss: 0.2093 - val_accuracy: 0.9414\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9524 - val_loss: 0.2205 - val_accuracy: 0.9368\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9537 - val_loss: 0.2462 - val_accuracy: 0.9284\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1493 - accuracy: 0.9523 - val_loss: 0.2557 - val_accuracy: 0.9338\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1539 - accuracy: 0.9505 - val_loss: 0.2407 - val_accuracy: 0.9292\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1477 - accuracy: 0.9497 - val_loss: 0.2160 - val_accuracy: 0.9397\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.9541 - val_loss: 0.2222 - val_accuracy: 0.9376\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9557 - val_loss: 0.2444 - val_accuracy: 0.9238\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 0.9496 - val_loss: 0.2086 - val_accuracy: 0.9451\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1324 - accuracy: 0.9537 - val_loss: 0.2137 - val_accuracy: 0.9477\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1250 - accuracy: 0.9580 - val_loss: 0.2194 - val_accuracy: 0.9430\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1287 - accuracy: 0.9600 - val_loss: 0.2371 - val_accuracy: 0.9313\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1271 - accuracy: 0.9578 - val_loss: 0.2165 - val_accuracy: 0.9426\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1274 - accuracy: 0.9578 - val_loss: 0.2130 - val_accuracy: 0.9418\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1155 - accuracy: 0.9591 - val_loss: 0.2793 - val_accuracy: 0.9229\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1316 - accuracy: 0.9567 - val_loss: 0.2249 - val_accuracy: 0.9389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "\n",
        "scores = sub_model_multi.evaluate(test_inputs, test_y, verbose=0)\n",
        "\n",
        "scores\n",
        "\n",
        "# In results, first is loss, second is accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0901-p4Jjd5",
        "outputId": "f67efff8-0ae1-4d26-c0d5-04e254dd055c"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22491976618766785, 0.9388609528541565]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sub Model with more Hidden Layers (Optimizer: RMSprop)**"
      ],
      "metadata": {
        "id": "ZNLBrSHxOuYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the model: for multi-class\n",
        "\n",
        "sub_model_multi_1 = keras.models.Sequential()\n",
        "\n",
        "sub_model_multi_1.add(keras.layers.Input(shape=80))\n",
        "sub_model_multi_1.add(keras.layers.Dense(25, activation='relu'))\n",
        "sub_model_multi_1.add(keras.layers.Dense(75, activation='relu'))\n",
        "sub_model_multi_1.add(keras.layers.Dense(150, activation='relu'))\n",
        "sub_model_multi_1.add(keras.layers.Dense(75, activation='relu'))\n",
        "sub_model_multi_1.add(keras.layers.Dense(25, activation='relu'))\n",
        "sub_model_multi_1.add(keras.layers.Dense(5, activation='softmax'))\n",
        "#final layer: there has to be 5 nodes with softmax layer since we have 5 categories in the target label.\n"
      ],
      "metadata": {
        "id": "GgnRosRXJjhk"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "\n",
        "#Optimizer using Adam optimizer\n",
        "adam = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "\n",
        "sub_model_multi_1.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "zS6AgSXvJjkr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "history = sub_model_multi_1.fit(train_inputs, train_y, \n",
        "                    validation_data=(test_inputs, test_y), \n",
        "                    epochs=75, batch_size=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRM-cGCWPBR4",
        "outputId": "cd08f540-03d0-4d8a-ff47-d1dba146ff59"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "12/12 [==============================] - 2s 51ms/step - loss: 1.3634 - accuracy: 0.4691 - val_loss: 1.0859 - val_accuracy: 0.6034\n",
            "Epoch 2/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.1615 - accuracy: 0.5560 - val_loss: 1.1583 - val_accuracy: 0.4883\n",
            "Epoch 3/75\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1.0905 - accuracy: 0.5711 - val_loss: 0.8549 - val_accuracy: 0.6859\n",
            "Epoch 4/75\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.8905 - accuracy: 0.6834 - val_loss: 0.8089 - val_accuracy: 0.7450\n",
            "Epoch 5/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.9075 - accuracy: 0.7091 - val_loss: 0.6382 - val_accuracy: 0.7839\n",
            "Epoch 6/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.9951 - accuracy: 0.6531 - val_loss: 0.7155 - val_accuracy: 0.7617\n",
            "Epoch 7/75\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6958 - accuracy: 0.7654 - val_loss: 0.9790 - val_accuracy: 0.6311\n",
            "Epoch 8/75\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.7569 - accuracy: 0.7441 - val_loss: 0.7141 - val_accuracy: 0.7881\n",
            "Epoch 9/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6551 - accuracy: 0.7803 - val_loss: 0.5573 - val_accuracy: 0.8107\n",
            "Epoch 10/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7067 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.8245\n",
            "Epoch 11/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6839 - accuracy: 0.7834 - val_loss: 0.5447 - val_accuracy: 0.8195\n",
            "Epoch 12/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6035 - accuracy: 0.7985 - val_loss: 0.5797 - val_accuracy: 0.8484\n",
            "Epoch 13/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6086 - accuracy: 0.7994 - val_loss: 0.4655 - val_accuracy: 0.8589\n",
            "Epoch 14/75\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.5898 - accuracy: 0.8044 - val_loss: 0.5742 - val_accuracy: 0.8384\n",
            "Epoch 15/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.5778 - accuracy: 0.8089 - val_loss: 0.5189 - val_accuracy: 0.8120\n",
            "Epoch 16/75\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5950 - accuracy: 0.7954 - val_loss: 0.7889 - val_accuracy: 0.7299\n",
            "Epoch 17/75\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5864 - accuracy: 0.8108 - val_loss: 0.6214 - val_accuracy: 0.7927\n",
            "Epoch 18/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5055 - accuracy: 0.8250 - val_loss: 0.5692 - val_accuracy: 0.8053\n",
            "Epoch 19/75\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5149 - accuracy: 0.8268 - val_loss: 0.5681 - val_accuracy: 0.8191\n",
            "Epoch 20/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5311 - accuracy: 0.8125 - val_loss: 0.6541 - val_accuracy: 0.7718\n",
            "Epoch 21/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4525 - accuracy: 0.8480 - val_loss: 0.5561 - val_accuracy: 0.8132\n",
            "Epoch 22/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5710 - accuracy: 0.8155 - val_loss: 0.5379 - val_accuracy: 0.8128\n",
            "Epoch 23/75\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.4689 - accuracy: 0.8424 - val_loss: 0.4465 - val_accuracy: 0.8635\n",
            "Epoch 24/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4697 - accuracy: 0.8335 - val_loss: 0.5884 - val_accuracy: 0.8065\n",
            "Epoch 25/75\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4866 - accuracy: 0.8415 - val_loss: 0.7667 - val_accuracy: 0.7596\n",
            "Epoch 26/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.4489 - accuracy: 0.8566 - val_loss: 0.4716 - val_accuracy: 0.8421\n",
            "Epoch 27/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4281 - accuracy: 0.8530 - val_loss: 0.3604 - val_accuracy: 0.8874\n",
            "Epoch 28/75\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5956 - accuracy: 0.8117 - val_loss: 0.5515 - val_accuracy: 0.8287\n",
            "Epoch 29/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4657 - accuracy: 0.8460 - val_loss: 0.4515 - val_accuracy: 0.8668\n",
            "Epoch 30/75\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3639 - accuracy: 0.8783 - val_loss: 0.3801 - val_accuracy: 0.8706\n",
            "Epoch 31/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3771 - accuracy: 0.8765 - val_loss: 0.4534 - val_accuracy: 0.8204\n",
            "Epoch 32/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4241 - accuracy: 0.8467 - val_loss: 0.4793 - val_accuracy: 0.8836\n",
            "Epoch 33/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3648 - accuracy: 0.8769 - val_loss: 0.4630 - val_accuracy: 0.8551\n",
            "Epoch 34/75\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4551 - accuracy: 0.8496 - val_loss: 0.4234 - val_accuracy: 0.8534\n",
            "Epoch 35/75\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3336 - accuracy: 0.8920 - val_loss: 0.5553 - val_accuracy: 0.8421\n",
            "Epoch 36/75\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4455 - accuracy: 0.8512 - val_loss: 0.4945 - val_accuracy: 0.8367\n",
            "Epoch 37/75\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3796 - accuracy: 0.8769 - val_loss: 0.3711 - val_accuracy: 0.8857\n",
            "Epoch 38/75\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3349 - accuracy: 0.8923 - val_loss: 0.9567 - val_accuracy: 0.7466\n",
            "Epoch 39/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4542 - accuracy: 0.8537 - val_loss: 0.4048 - val_accuracy: 0.8836\n",
            "Epoch 40/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3237 - accuracy: 0.8943 - val_loss: 0.5792 - val_accuracy: 0.8442\n",
            "Epoch 41/75\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.3798 - accuracy: 0.8771 - val_loss: 0.7368 - val_accuracy: 0.7676\n",
            "Epoch 42/75\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3560 - accuracy: 0.8839 - val_loss: 0.4132 - val_accuracy: 0.8744\n",
            "Epoch 43/75\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3410 - accuracy: 0.8844 - val_loss: 0.3860 - val_accuracy: 0.8894\n",
            "Epoch 44/75\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3716 - accuracy: 0.8715 - val_loss: 0.3187 - val_accuracy: 0.9146\n",
            "Epoch 45/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2758 - accuracy: 0.9140 - val_loss: 0.4066 - val_accuracy: 0.8781\n",
            "Epoch 46/75\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3295 - accuracy: 0.8959 - val_loss: 0.3482 - val_accuracy: 0.9045\n",
            "Epoch 47/75\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3484 - accuracy: 0.8894 - val_loss: 0.3904 - val_accuracy: 0.8681\n",
            "Epoch 48/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.2842 - accuracy: 0.9043 - val_loss: 0.3980 - val_accuracy: 0.8832\n",
            "Epoch 49/75\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4153 - accuracy: 0.8681 - val_loss: 0.3376 - val_accuracy: 0.9016\n",
            "Epoch 50/75\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2710 - accuracy: 0.9101 - val_loss: 0.4769 - val_accuracy: 0.8656\n",
            "Epoch 51/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3785 - accuracy: 0.8781 - val_loss: 0.2811 - val_accuracy: 0.9255\n",
            "Epoch 52/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.2745 - accuracy: 0.9095 - val_loss: 0.4377 - val_accuracy: 0.8534\n",
            "Epoch 53/75\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.2705 - accuracy: 0.9087 - val_loss: 0.5267 - val_accuracy: 0.8823\n",
            "Epoch 54/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3398 - accuracy: 0.8880 - val_loss: 0.3362 - val_accuracy: 0.9158\n",
            "Epoch 55/75\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.2514 - accuracy: 0.9191 - val_loss: 0.5260 - val_accuracy: 0.8291\n",
            "Epoch 56/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3853 - accuracy: 0.8679 - val_loss: 0.2974 - val_accuracy: 0.9217\n",
            "Epoch 57/75\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2421 - accuracy: 0.9210 - val_loss: 0.3020 - val_accuracy: 0.9229\n",
            "Epoch 58/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3448 - accuracy: 0.8868 - val_loss: 0.3061 - val_accuracy: 0.9171\n",
            "Epoch 59/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2476 - accuracy: 0.9201 - val_loss: 0.3318 - val_accuracy: 0.9091\n",
            "Epoch 60/75\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.2980 - accuracy: 0.9049 - val_loss: 0.4357 - val_accuracy: 0.8660\n",
            "Epoch 61/75\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2371 - accuracy: 0.9235 - val_loss: 0.6924 - val_accuracy: 0.7680\n",
            "Epoch 62/75\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3327 - accuracy: 0.8918 - val_loss: 0.4083 - val_accuracy: 0.8874\n",
            "Epoch 63/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.2210 - accuracy: 0.9270 - val_loss: 0.3195 - val_accuracy: 0.9296\n",
            "Epoch 64/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3233 - accuracy: 0.8954 - val_loss: 0.2701 - val_accuracy: 0.9213\n",
            "Epoch 65/75\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2516 - accuracy: 0.9124 - val_loss: 0.3602 - val_accuracy: 0.9087\n",
            "Epoch 66/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2689 - accuracy: 0.9169 - val_loss: 0.4709 - val_accuracy: 0.8756\n",
            "Epoch 67/75\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2575 - accuracy: 0.9189 - val_loss: 0.3469 - val_accuracy: 0.9162\n",
            "Epoch 68/75\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2709 - accuracy: 0.9112 - val_loss: 0.3502 - val_accuracy: 0.8857\n",
            "Epoch 69/75\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.2512 - accuracy: 0.9103 - val_loss: 0.3109 - val_accuracy: 0.9054\n",
            "Epoch 70/75\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.1962 - accuracy: 0.9341 - val_loss: 0.4113 - val_accuracy: 0.8853\n",
            "Epoch 71/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.5570 - accuracy: 0.8586 - val_loss: 0.3389 - val_accuracy: 0.8928\n",
            "Epoch 72/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1997 - accuracy: 0.9354 - val_loss: 0.3138 - val_accuracy: 0.9112\n",
            "Epoch 73/75\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1944 - accuracy: 0.9354 - val_loss: 0.2891 - val_accuracy: 0.9255\n",
            "Epoch 74/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.2352 - accuracy: 0.9198 - val_loss: 0.2650 - val_accuracy: 0.9217\n",
            "Epoch 75/75\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.2770 - accuracy: 0.9101 - val_loss: 0.3422 - val_accuracy: 0.9037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "\n",
        "scores = sub_model_multi_1.evaluate(test_inputs, test_y, verbose=0)\n",
        "\n",
        "scores\n",
        "\n",
        "# In results, first is loss, second is accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NMd2wubPBVC",
        "outputId": "e974d168-5331-427f-f212-5b57642f2eaf"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34219375252723694, 0.9036850929260254]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the accuracy from model.evaluate\n",
        "\n",
        "print(\"%s: %.2f\" % (sub_model_multi_1.metrics_names[0], scores[0]))\n",
        "print(\"%s: %.2f%%\" % (sub_model_multi_1.metrics_names[1], scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNUDttDtPBXk",
        "outputId": "317b02ff-3699-402f-b761-4a8cce5263e8"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.34\n",
            "accuracy: 90.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jOJ_FtDDPBZY"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oVLl3UJzPBfX"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4cjqghvoUDc"
      },
      "source": [
        "# Build a sequential shallow LSTM Model (with only one LSTM layer) (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1"
      ],
      "metadata": {
        "id": "7exsmiY1RSfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert input variables to a 2-D array with float data type\n",
        "train_x= np.array(train_inputs)\n",
        "test_x= np.array(test_inputs)\n",
        "\n",
        "train_x = train_x.astype(np.float32)\n",
        "test_x = test_x.astype(np.float32)\n",
        "\n",
        "train_y = np.array(train_y)\n",
        "train_y = np.reshape(train_y,(train_y.shape[0],))\n",
        "test_y = np.array(test_y)\n",
        "test_y = np.reshape(test_y,(test_y.shape[0],))\n",
        "\n",
        "train_y = train_y.astype(np.int32)\n",
        "test_y = test_y.astype(np.int32)"
      ],
      "metadata": {
        "id": "2EdiXM5xUjT8"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras expects a different input format:\n",
        "#Data needs to have 3 dimensions.\n",
        "#Here i am reshaping the data to the  sequence format for the LSTM   \n",
        "\n",
        "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
        "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n",
        "\n"
      ],
      "metadata": {
        "id": "76KN8WwSUjcV"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the shapes of the data.\n",
        "\n",
        "train_x.shape, train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIz4tbCiUjfa",
        "outputId": "931c3f40-c108-4b18-c3f2-6b37132e5e23"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5572, 80, 1), (5572,))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the shapes of the data.\n",
        "\n",
        "test_x.shape, test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyQAh0yYXFzt",
        "outputId": "0d35bd22-8a1e-4c56-c55d-7aea09dc24b2"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2388, 80, 1), (2388,))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8depIfpZOZl",
        "outputId": "707e4a6f-513b-4260-b6ea-18bd8f529a14"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 2, 0, ..., 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AsxB2jOMNe66"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Call Backs\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "\n",
        "callback = [earlystop]"
      ],
      "metadata": {
        "id": "l2IYcz4xUji-"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nEMhMSh3NeIJ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "bMHInsQNoUDc"
      },
      "outputs": [],
      "source": [
        "LSTM_model = keras.models.Sequential([\n",
        "    keras.layers.LSTM(10, activation=\"sigmoid\", input_shape=(80, 1)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCwoky6QoUDc",
        "outputId": "567afb72-9fe0-4841-c64f-9c0715b488cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "175/175 [==============================] - 8s 37ms/step - loss: -1.2171 - accuracy: 0.0000e+00 - val_loss: -1.3840 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "175/175 [==============================] - 8s 47ms/step - loss: -3.1187 - accuracy: 0.2134 - val_loss: -1.8547 - val_accuracy: 0.3120\n",
            "Epoch 3/20\n",
            "175/175 [==============================] - 5s 31ms/step - loss: -3.3037 - accuracy: 0.2809 - val_loss: -1.8506 - val_accuracy: 0.2571\n",
            "Epoch 4/20\n",
            "175/175 [==============================] - 6s 34ms/step - loss: -3.3027 - accuracy: 0.2662 - val_loss: -1.8654 - val_accuracy: 0.2458\n",
            "Epoch 5/20\n",
            "175/175 [==============================] - 5s 29ms/step - loss: -3.3107 - accuracy: 0.2441 - val_loss: -1.8671 - val_accuracy: 0.1897\n",
            "Epoch 6/20\n",
            "175/175 [==============================] - 5s 30ms/step - loss: -3.3196 - accuracy: 0.2225 - val_loss: -1.8965 - val_accuracy: 0.2064\n",
            "Epoch 7/20\n",
            "175/175 [==============================] - 5s 30ms/step - loss: -3.3307 - accuracy: 0.2053 - val_loss: -1.9140 - val_accuracy: 0.2106\n",
            "Epoch 8/20\n",
            "175/175 [==============================] - 6s 35ms/step - loss: -3.3429 - accuracy: 0.1872 - val_loss: -1.9333 - val_accuracy: 0.2098\n",
            "Epoch 9/20\n",
            "175/175 [==============================] - 7s 40ms/step - loss: -3.3572 - accuracy: 0.1875 - val_loss: -1.9536 - val_accuracy: 0.1792\n",
            "Epoch 10/20\n",
            "175/175 [==============================] - 5s 31ms/step - loss: -3.3764 - accuracy: 0.1818 - val_loss: -1.9716 - val_accuracy: 0.1993\n",
            "Epoch 11/20\n",
            "175/175 [==============================] - 5s 31ms/step - loss: -3.3967 - accuracy: 0.1849 - val_loss: -2.0003 - val_accuracy: 0.1922\n",
            "Epoch 12/20\n",
            "175/175 [==============================] - 5s 31ms/step - loss: -3.4161 - accuracy: 0.1700 - val_loss: -2.0173 - val_accuracy: 0.2391\n",
            "Epoch 13/20\n",
            "175/175 [==============================] - 5s 30ms/step - loss: -3.4381 - accuracy: 0.1807 - val_loss: -2.0746 - val_accuracy: 0.1696\n",
            "Epoch 14/20\n",
            "175/175 [==============================] - 6s 33ms/step - loss: -3.4605 - accuracy: 0.1617 - val_loss: -2.1053 - val_accuracy: 0.1562\n",
            "Epoch 15/20\n",
            "175/175 [==============================] - 10s 57ms/step - loss: -3.4803 - accuracy: 0.1653 - val_loss: -2.1180 - val_accuracy: 0.1930\n",
            "Epoch 16/20\n",
            "175/175 [==============================] - 9s 50ms/step - loss: -3.5065 - accuracy: 0.1608 - val_loss: -2.1547 - val_accuracy: 0.1704\n",
            "Epoch 17/20\n",
            "175/175 [==============================] - 8s 43ms/step - loss: -3.5310 - accuracy: 0.1705 - val_loss: -2.1873 - val_accuracy: 0.1876\n",
            "Epoch 18/20\n",
            "175/175 [==============================] - 5s 30ms/step - loss: -3.5523 - accuracy: 0.1604 - val_loss: -2.2305 - val_accuracy: 0.1604\n",
            "Epoch 19/20\n",
            "175/175 [==============================] - 6s 32ms/step - loss: -3.5783 - accuracy: 0.1578 - val_loss: -2.2526 - val_accuracy: 0.1738\n",
            "Epoch 20/20\n",
            "175/175 [==============================] - 5s 30ms/step - loss: -3.6003 - accuracy: 0.1644 - val_loss: -2.2899 - val_accuracy: 0.1591\n"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
        "\n",
        "LSTM_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = LSTM_model.fit(train_x, train_y, epochs=20,\n",
        "                   validation_data = (test_x, test_y), callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOUot1ZYoUDc",
        "outputId": "b7191d82-4a0c-40e3-f159-129b6871bd07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-2.2898786067962646, 0.15912897884845734]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "# evaluate the model\n",
        "\n",
        "scores = LSTM_model.evaluate(test_x, test_y, verbose=0)\n",
        "\n",
        "scores\n",
        "\n",
        "# In results, first is loss, second is accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the accuracy from model.evaluate\n",
        "\n",
        "print(\"%s: %.2f\" % (LSTM_model.metrics_names[0], scores[0]))\n",
        "print(\"%s: %.2f%%\" % (LSTM_model.metrics_names[1], scores[1]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVebSjyKQa-w",
        "outputId": "45a3271f-1f7e-46da-9786-fa9b59740087"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.34\n",
            "accuracy: 90.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GZ7Vf7qmQbB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "25WdEuvWQbEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a9CfG7RnQbHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K0r0Gz-YQbP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Phd8eh1LoUDc"
      },
      "source": [
        "# Build a sequential deep LSTM Model (with only two LSTM layers) (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d57x6MToUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNt6DYoZoUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AzeG7rloUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwMRyMrfoUDc"
      },
      "source": [
        "# Build a sequential shallow GRU Model (with only one GRU layer) (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NauGCzoUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pll8_oEmoUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fn5RxT7oUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV4y7wRUoUDc"
      },
      "source": [
        "# Build a sequential deep GRU Model (with only two GRU layers) (2 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaP0yY_PoUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF53rL9toUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_92e-y6oUDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0cicxKqoUDc"
      },
      "source": [
        "# Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxk69s4JoUDc"
      },
      "source": [
        "## List the test values of each model you built (0.5 points)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "uMWz-urUoUDc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7D_zamHoUDc"
      },
      "source": [
        "## Which model performs the best and why? (0.5 points) \n",
        "## How does it compare to baseline? (0.5 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "KxEf-SHKoUDc"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}